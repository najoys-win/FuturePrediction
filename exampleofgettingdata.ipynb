{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef90d4a-8ac7-4ebe-9700-e851805b9de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failboat\n",
      "UC9mBJdNZxwE-La5vX0Kozvg\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "api_key = 'AIzaSyAB7IhXukv3OUesHkDQnWTLB-8lIZqON1I'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "request = youtube.search().list(\n",
    "    q='Failboat', # the name of the channel \n",
    "    part='snippet',\n",
    "    type='channel',\n",
    "    maxResults=1\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "for item in response.get('items', []):\n",
    "    print(item['snippet']['title'])\n",
    "    print(item['id']['channelId'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4594af-bca1-4548-8fad-e4c8a42efa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'Failboat.csv'.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "api_key = 'AIzaSyAB7IhXukv3OUesHkDQnWTLB-8lIZqON1I'\n",
    "channel_id = 'UC9mBJdNZxwE-La5vX0Kozvg'  #Failboat\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def get_videos_by_date(channel_id, start_date, end_date):\n",
    "    all_videos = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "            type=\"video\",\n",
    "            publishedAfter=start_date,\n",
    "            publishedBefore=end_date\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Collecting video IDs\n",
    "        video_ids = [item['id']['videoId'] for item in response.get('items', [])]\n",
    "        all_videos.extend(video_ids)\n",
    "        \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_videos\n",
    "\n",
    "start_date = datetime(2022, 1, 1).isoformat(\"T\") + \"Z\"\n",
    "end_date = datetime(2024, 3, 31).isoformat(\"T\") + \"Z\"\n",
    "\n",
    "# Fetch video IDs\n",
    "video_ids = get_videos_by_date(channel_id, start_date, end_date)\n",
    "\n",
    "# Now fetch details for each video ID\n",
    "def get_video_details(video_ids):\n",
    "    videos = []\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,statistics,contentDetails\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        videos.extend(response.get('items', []))\n",
    "    return videos\n",
    "import re\n",
    "\n",
    "def parse_duration(duration):\n",
    "    # Regex to extract hours, minutes, seconds\n",
    "    pattern = re.compile('PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?')\n",
    "    hours, minutes, seconds = pattern.match(duration).groups()\n",
    "    hours = int(hours) if hours else 0\n",
    "    minutes = int(minutes) if minutes else 0\n",
    "    seconds = int(seconds) if seconds else 0\n",
    "    total_minutes = hours * 60 + minutes + seconds / 60\n",
    "    return round(total_minutes, 2)\n",
    "\n",
    "\n",
    "\n",
    "# Get details for fetched video IDs\n",
    "video_details = get_video_details(video_ids)\n",
    "\n",
    "df = pd.DataFrame([{\n",
    "    'Title': video['snippet']['title'],\n",
    "    'PublishedAt': video['snippet']['publishedAt'],\n",
    "    'ViewCount': video['statistics'].get('viewCount', 0),\n",
    "    'LikeCount': video['statistics'].get('likeCount', 0),\n",
    "    'DislikeCount': video['statistics'].get('dislikeCount', 0),\n",
    "    'CommentCount': video['statistics'].get('commentCount', 0),\n",
    "    'Duration': parse_duration(video['contentDetails']['duration']),\n",
    "    'URL': f\"https://www.youtube.com/watch?v={video['id']}\"\n",
    "} for video in video_details])\n",
    "\n",
    "df.to_csv('D:/Master Project/Failboat.csv', index=False)\n",
    "print(\"Data saved to 'Failboat.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4123f-bfea-45fc-96db-b6ef8057915f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f29f0c-7e84-44f9-8a2d-8cc7c3a7f823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
